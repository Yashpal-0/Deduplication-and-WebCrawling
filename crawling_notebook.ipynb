{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Crawling Assignment Activity 2.2\n",
        "\n",
        "This notebook interacts with the local crawling assignment server (running at `http://localhost:3000`) to\n",
        "- discover the site graph with minimal page visits,\n",
        "- track `node_id` updates for each page, and\n",
        "- estimate PageRank scores over the discovered link structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Helper Functions\n",
        "\n",
        "The web server returns JSON responses. We use `requests` for HTTP and utilities for crawling and scoring.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install beautifulsoup4 --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "import re\n",
        "from collections import deque, defaultdict\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Set, Tuple\n",
        "import pandas as pd\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "BASE_URL = \"http://localhost:3000\"\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"CrawlerAssignmentBot/1.2\",\n",
        "    \"Accept\": \"text/html,application/json\",\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'path': '/',\n",
              " 'page_id': 'page_1yi8d2sx',\n",
              " 'node_id': '158pgabnwj9a',\n",
              " 'last_updated': '2025-11-17 19:48:31 UTC',\n",
              " 'history': [],\n",
              " 'links': ['/page_28kxnvap',\n",
              "  '/page_8qmlk6n0',\n",
              "  '/page_ds6a104p',\n",
              "  '/page_ozgkl2gr',\n",
              "  '/page_rqodhkwd']}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def fetch_page(path: str = \"/\") -> str:\n",
        "    url = BASE_URL.rstrip(\"/\") + path\n",
        "    response = session.get(url, timeout=10)\n",
        "    response.raise_for_status()\n",
        "    return response.text\n",
        "\n",
        "\n",
        "def parse_page(content: str, path: str) -> dict:\n",
        "    soup = BeautifulSoup(content, \"html.parser\")\n",
        "\n",
        "    page_id_text = soup.select_one(\".page-id\")\n",
        "    page_id = \"\"\n",
        "    if page_id_text:\n",
        "        page_id = page_id_text.get_text(strip=True).split(\":\")[-1].strip()\n",
        "\n",
        "    node_id_elem = soup.select_one(\".node-id b\")\n",
        "    node_id = node_id_elem.get_text(strip=True) if node_id_elem else \"\"\n",
        "\n",
        "    last_updated_elem = soup.select_one(\".last-updated\")\n",
        "    last_updated = \"\"\n",
        "    if last_updated_elem:\n",
        "        last_updated = last_updated_elem.get_text(strip=True)\n",
        "        if \":\" in last_updated:\n",
        "            last_updated = last_updated.split(\":\", 1)[-1].strip()\n",
        "\n",
        "    history_entries: List[dict] = []\n",
        "    history_container = soup.select_one(\"details\")\n",
        "    if history_container:\n",
        "        for entry in history_container.select(\"div\"):\n",
        "            text = entry.get_text(strip=True)\n",
        "            text = text.strip(\"\\u0007 \\n\\r\\t\")\n",
        "            match = re.match(r\"([A-Za-z0-9]+)\\s*\\(([^)]+)\\)\", text)\n",
        "            if match:\n",
        "                history_entries.append({\n",
        "                    \"node_id\": match.group(1),\n",
        "                    \"timestamp\": match.group(2),\n",
        "                })\n",
        "\n",
        "    outgoing_links: List[str] = []\n",
        "    for link in soup.select(\"a.file-link\"):\n",
        "        href = link.get(\"href\")\n",
        "        if href and href.startswith(\"/page_\"):\n",
        "            outgoing_links.append(href)\n",
        "    outgoing_links = sorted(set(outgoing_links))\n",
        "\n",
        "    return {\n",
        "        \"path\": path,\n",
        "        \"page_id\": page_id,\n",
        "        \"node_id\": node_id,\n",
        "        \"last_updated\": last_updated,\n",
        "        \"history\": history_entries,\n",
        "        \"links\": outgoing_links,\n",
        "    }\n",
        "\n",
        "\n",
        "root_html = fetch_page(\"/\")\n",
        "root_parsed = parse_page(root_html, \"/\")\n",
        "root_parsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class PageState:\n",
        "    page_id: str\n",
        "    path: str\n",
        "    last_node_id: str\n",
        "    last_updated_at: str\n",
        "    history: List[dict] = field(default_factory=list)\n",
        "    outgoing: List[str] = field(default_factory=list)\n",
        "    last_fetched_ts: float = field(default_factory=time.time)\n",
        "    last_changed_ts: float = field(default_factory=time.time)\n",
        "    updates_detected: int = 0\n",
        "\n",
        "    def differs_from(self, node_id: str, last_updated: str, history: List[dict]) -> bool:\n",
        "        if node_id != self.last_node_id:\n",
        "            return True\n",
        "        if last_updated and last_updated != self.last_updated_at:\n",
        "            return True\n",
        "        if len(history) != len(self.history):\n",
        "            return True\n",
        "        if history and self.history:\n",
        "            return history[-1] != self.history[-1]\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EfficientCrawler:\n",
        "    \"\"\"\n",
        "    Optimized crawler with the following efficiency improvements:\n",
        "    1. Path normalization caching to avoid repeated string operations\n",
        "    2. Seen paths tracking (set) for O(1) duplicate detection vs O(n) queue checks\n",
        "    3. Time caching to reduce system calls\n",
        "    4. Selective logging (only new/changed pages) to reduce memory\n",
        "    5. Optimized refresh: single pass filter + slice instead of break\n",
        "    6. Efficient graph building: set operations instead of unions\n",
        "    7. PageRank optimization: pre-compute sink contributions, separate sink/non-sink processing\n",
        "    8. Single-pass summary calculation\n",
        "    \"\"\"\n",
        "    def __init__(self, seed_path: str = \"/\", revisit_window: float = 120.0):\n",
        "        self.seed_path = seed_path\n",
        "        self.revisit_window = revisit_window\n",
        "        self.pages: Dict[str, PageState] = {}\n",
        "        self.graph: Dict[str, Set[str]] = defaultdict(set)\n",
        "        self.page_visits = 0\n",
        "        self.node_updates = 0\n",
        "        self.fetch_log: List[dict] = []\n",
        "        # Optimization: Track seen paths to avoid duplicate queue entries\n",
        "        self._seen_paths: Set[str] = set()\n",
        "        # Optimization: Cache normalized paths\n",
        "        self._path_cache: Dict[str, str] = {}\n",
        "\n",
        "    def normalize_path(self, path: str) -> str:\n",
        "        # Use cache to avoid repeated normalization\n",
        "        if path in self._path_cache:\n",
        "            return self._path_cache[path]\n",
        "        \n",
        "        original_path = path\n",
        "        if path.startswith(\"http://\") or path.startswith(\"https://\"):\n",
        "            if path.startswith(BASE_URL):\n",
        "                path = path[len(BASE_URL):]\n",
        "            else:\n",
        "                self._path_cache[original_path] = path\n",
        "                return path  # external link\n",
        "        if not path.startswith(\"/\"):\n",
        "            path = \"/\" + path\n",
        "        \n",
        "        self._path_cache[original_path] = path\n",
        "        return path\n",
        "\n",
        "    def enqueue_links(self, path: str, links: List[str], queue: deque):\n",
        "        normalized_links = []\n",
        "        for link in links:\n",
        "            normalized = self.normalize_path(link)\n",
        "            if not normalized.startswith(\"/\"):\n",
        "                continue  # skip external\n",
        "            normalized_links.append(normalized)\n",
        "            # Optimization: Use set lookup instead of checking queue\n",
        "            if normalized not in self._seen_paths:\n",
        "                self._seen_paths.add(normalized)\n",
        "                queue.append(normalized)\n",
        "        self.graph[path] = set(normalized_links)\n",
        "\n",
        "    def fetch_and_update(self, path: str) -> Tuple[PageState, bool]:\n",
        "        content = fetch_page(path)\n",
        "        parsed = parse_page(content, path)\n",
        "        self.page_visits += 1\n",
        "\n",
        "        page_id = parsed.get(\"page_id\", \"\")\n",
        "        node_id = parsed.get(\"node_id\", \"\")\n",
        "        history = parsed.get(\"history\", [])\n",
        "        outgoing = parsed.get(\"links\", [])\n",
        "        last_timestamp = parsed.get(\"last_updated\", \"\")\n",
        "\n",
        "        state = self.pages.get(path)\n",
        "        now = time.time()\n",
        "        is_new = state is None\n",
        "        changed = False\n",
        "\n",
        "        if state is None:\n",
        "            state = PageState(\n",
        "                page_id=page_id,\n",
        "                path=path,\n",
        "                last_node_id=node_id,\n",
        "                last_updated_at=last_timestamp,\n",
        "                history=history,\n",
        "                outgoing=outgoing,\n",
        "                last_fetched_ts=now,\n",
        "                last_changed_ts=now,\n",
        "            )\n",
        "            self.pages[path] = state\n",
        "            self._seen_paths.add(path)  # Mark as seen\n",
        "        else:\n",
        "            state.page_id = page_id or state.page_id\n",
        "            if state.differs_from(node_id, last_timestamp, history):\n",
        "                changed = True\n",
        "                state.last_node_id = node_id\n",
        "                state.last_updated_at = last_timestamp\n",
        "                state.history = history\n",
        "                state.last_changed_ts = now\n",
        "                state.updates_detected += 1\n",
        "                self.node_updates += 1\n",
        "            state.outgoing = outgoing\n",
        "            state.last_fetched_ts = now\n",
        "\n",
        "        self.graph[path] = set(outgoing)\n",
        "        # Optimization: Only log if needed (reduce memory)\n",
        "        if is_new or changed:\n",
        "            self.fetch_log.append({\n",
        "                \"path\": path,\n",
        "                \"timestamp\": now,\n",
        "                \"is_new\": is_new,\n",
        "                \"changed\": (changed and not is_new),\n",
        "            })\n",
        "        return state, (changed and not is_new)\n",
        "\n",
        "    def crawl(self, max_visits: int = 5000):\n",
        "        queue: deque[str] = deque([self.seed_path])\n",
        "        visited: Set[str] = set()\n",
        "        self._seen_paths.add(self.seed_path)\n",
        "        current_time = time.time()\n",
        "\n",
        "        while queue and self.page_visits < max_visits:\n",
        "            path = queue.popleft()\n",
        "            state = self.pages.get(path)\n",
        "\n",
        "            should_fetch = False\n",
        "            if state is None:\n",
        "                should_fetch = True\n",
        "            else:\n",
        "                # Optimization: Cache current time to avoid repeated calls\n",
        "                current_time = time.time()\n",
        "                if current_time - state.last_fetched_ts >= self.revisit_window:\n",
        "                    should_fetch = True\n",
        "\n",
        "            if not should_fetch:\n",
        "                continue\n",
        "\n",
        "            state, _ = self.fetch_and_update(path)\n",
        "            visited.add(path)\n",
        "            self.enqueue_links(path, state.outgoing, queue)\n",
        "\n",
        "        return visited\n",
        "\n",
        "    def refresh_due_pages(self, max_visits: int = 1000):\n",
        "        # Optimization: Calculate current time once\n",
        "        current_time = time.time()\n",
        "        # Optimization: Use list comprehension with filter for better performance\n",
        "        due_pages = [\n",
        "            path for path, state in self.pages.items()\n",
        "            if current_time - state.last_fetched_ts >= self.revisit_window\n",
        "        ]\n",
        "        # Optimization: Sort by staleness (oldest first) for better refresh order\n",
        "        due_pages.sort(key=lambda p: current_time - self.pages[p].last_fetched_ts, reverse=True)\n",
        "        \n",
        "        refreshed = []\n",
        "        updates_detected = 0\n",
        "        for path in due_pages[:max_visits]:  # Slice instead of break\n",
        "            _, updated = self.fetch_and_update(path)\n",
        "            refreshed.append(path)\n",
        "            if updated:\n",
        "                updates_detected += 1\n",
        "        return {\n",
        "            \"refreshed_paths\": refreshed,\n",
        "            \"updates_detected\": updates_detected,\n",
        "            \"fetches\": len(refreshed),\n",
        "        }\n",
        "\n",
        "    def build_pagerank_matrix(self):\n",
        "        # Optimization: Build node set more efficiently\n",
        "        all_nodes = set(self.graph.keys())\n",
        "        for dests in self.graph.values():\n",
        "            all_nodes.update(dests)\n",
        "        \n",
        "        nodes = sorted(all_nodes)\n",
        "        node_index = {node: idx for idx, node in enumerate(nodes)}\n",
        "        \n",
        "        # Optimization: Pre-allocate adjacency list\n",
        "        n = len(nodes)\n",
        "        adjacency = [[] for _ in range(n)]\n",
        "        \n",
        "        for src, dests in self.graph.items():\n",
        "            if src not in node_index:\n",
        "                continue\n",
        "            src_idx = node_index[src]\n",
        "            # Optimization: Use list comprehension with filter\n",
        "            adjacency[src_idx] = [node_index[d] for d in dests if d in node_index]\n",
        "        \n",
        "        return nodes, adjacency\n",
        "\n",
        "    def pagerank(self, damping: float = 0.85, max_iter: int = 100, tol: float = 1e-6):\n",
        "        nodes, adjacency = self.build_pagerank_matrix()\n",
        "        n = len(nodes)\n",
        "        if n == 0:\n",
        "            return {}\n",
        "        \n",
        "        pr = [1.0 / n] * n\n",
        "        teleport = (1.0 - damping) / n\n",
        "        sink_share = damping / n  # Pre-compute sink share\n",
        "\n",
        "        for iteration in range(max_iter):\n",
        "            new_pr = [teleport] * n\n",
        "            # Optimization: Pre-compute total sink contribution and add to all nodes once\n",
        "            sink_total = sum(pr[idx] for idx, neighbors in enumerate(adjacency) if not neighbors)\n",
        "            if sink_total > 0:\n",
        "                sink_contribution = sink_total * sink_share\n",
        "                for j in range(n):\n",
        "                    new_pr[j] += sink_contribution\n",
        "            \n",
        "            # Process non-sink nodes\n",
        "            for idx, neighbors in enumerate(adjacency):\n",
        "                if neighbors:  # Only process non-sinks\n",
        "                    share = damping * pr[idx] / len(neighbors)\n",
        "                    for dest_idx in neighbors:\n",
        "                        new_pr[dest_idx] += share\n",
        "            \n",
        "            # Optimization: Early convergence check with vectorized computation\n",
        "            delta = sum(abs(new_pr[i] - pr[i]) for i in range(n))\n",
        "            pr = new_pr\n",
        "            if delta < tol:\n",
        "                break\n",
        "        \n",
        "        return {nodes[i]: pr[i] for i in range(n)}\n",
        "\n",
        "    def summary(self) -> dict:\n",
        "        # Optimization: Single pass through pages\n",
        "        total_links = 0\n",
        "        unique_pages = len(self.pages)\n",
        "        for state in self.pages.values():\n",
        "            total_links += len(state.outgoing)\n",
        "        \n",
        "        return {\n",
        "            \"unique_pages\": unique_pages,\n",
        "            \"page_visits\": self.page_visits,\n",
        "            \"node_updates\": self.node_updates,\n",
        "            \"average_out_degree\": (total_links / unique_pages) if unique_pages else 0.0,\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# crawler = EfficientCrawler(seed_path=\"/\", revisit_window=5.0)\n",
        "# visited = crawler.crawl(max_visits=2000)\n",
        "# visited_count = len(visited)\n",
        "# initial_summary = crawler.summary()\n",
        "# visited_count, crawler.page_visits, initial_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "results_df not yet created. Run the cells above to create page_summary and merge with pagerank_df.\n"
          ]
        }
      ],
      "source": [
        "if 'results_df' in globals() and not results_df.empty:\n",
        "    results_df.sort_values(\"pagerank\", ascending=False).head(10)[[\"path\", \"pagerank\", \"updates_detected\", \"links\"]]\n",
        "else:\n",
        "    print(\"results_df not yet created. Run the cells above to create page_summary and merge with pagerank_df.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refresh Monitoring\n",
        "\n",
        "We periodically revisit pages (respecting the 5-second `revisit_window`) to track node-id churn while keeping the number of extra fetches low.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation Submission\n",
        "\n",
        "The assignment requires submitting evaluations to `/evaluate` endpoint:\n",
        "- First evaluation within 15 seconds of first visit\n",
        "- Subsequent evaluations at least every 15 seconds\n",
        "- All evaluations within 60 seconds of first visit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ submit_evaluation function fixed! Now uses state.page_id instead of path.\n"
          ]
        }
      ],
      "source": [
        "# FIX: Replace submit_evaluation with corrected version\n",
        "# The original was using path instead of actual page_id from state\n",
        "\n",
        "def submit_evaluation(crawler: EfficientCrawler, pagerank_scores: dict) -> dict:\n",
        "    entries = []\n",
        "    for path, state in crawler.pages.items():\n",
        "        # Use the actual page_id from the page state, not the path\n",
        "        page_id = state.page_id\n",
        "        if not page_id or not page_id.strip():\n",
        "            # Fallback: extract from path if page_id is missing\n",
        "            page_id = path.lstrip(\"/\")\n",
        "            if not page_id:\n",
        "                continue  # Skip root path if no page_id available\n",
        "        \n",
        "        latest_node_id = state.last_node_id\n",
        "        if not latest_node_id or not latest_node_id.strip():\n",
        "            continue  # Skip entries without valid node_id\n",
        "        \n",
        "        score = pagerank_scores.get(path, 0.0)\n",
        "        entries.append({\n",
        "            \"page_id\": page_id,\n",
        "            \"latest_node_id\": latest_node_id,\n",
        "            \"score\": float(score),\n",
        "        })\n",
        "    \n",
        "    if not entries:\n",
        "        return {\"error\": \"No valid entries to submit (all entries missing page_id or node_id)\"}\n",
        "    \n",
        "    payload = {\"entries\": entries}\n",
        "    try:\n",
        "        response = session.post(\n",
        "            f\"{BASE_URL}/evaluate\",\n",
        "            json=payload,\n",
        "            timeout=5,\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "        return result\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        # Try to get error details from response\n",
        "        try:\n",
        "            if hasattr(e, 'response') and e.response is not None:\n",
        "                error_detail = e.response.json()\n",
        "                return {\"error\": str(e), \"detail\": error_detail}\n",
        "        except:\n",
        "            pass\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "print(\"✓ submit_evaluation function fixed! Now uses state.page_id instead of path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Note on evaluation.bin\n",
        "\n",
        "The `evaluation.bin` file is created by the server (not the client) in the `/data` directory. According to the assignment instructions, it contains encrypted evaluation data for all evaluations submitted within the 60-second window. The file may be written:\n",
        "- After the 60-second window completes\n",
        "- When the server processes all submitted evaluations\n",
        "- The file location: `data/evaluation.bin` (if Docker volume is mounted correctly)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠ evaluation.bin not found yet.\n",
            "  The server creates this file after processing evaluations.\n",
            "  It may appear after the 60-second window completes.\n",
            "  Expected location: f:\\IIITH\\COURSEWORK\\Monsoon_2025_SEM_IX\\IRE\\assignment 2\\data\\evaluation.bin\n",
            "\n",
            "  To check manually:\n",
            "    - Local: data\\evaluation.bin\n",
            "    - Docker: /data/evaluation.bin (inside container)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "evaluation_file = Path(\"data/evaluation.bin\")\n",
        "if evaluation_file.exists():\n",
        "    file_size = evaluation_file.stat().st_size\n",
        "    file_time = evaluation_file.stat().st_mtime\n",
        "    print(f\"✓ evaluation.bin found!\")\n",
        "    print(f\"  Size: {file_size} bytes\")\n",
        "    print(f\"  Last modified: {time.ctime(file_time)}\")\n",
        "else:\n",
        "    print(\"⚠ evaluation.bin not found yet.\")\n",
        "    print(\"  The server creates this file after processing evaluations.\")\n",
        "    print(\"  It may appear after the 60-second window completes.\")\n",
        "    print(f\"  Expected location: {evaluation_file.absolute()}\")\n",
        "    print(\"\\n  To check manually:\")\n",
        "    print(f\"    - Local: {evaluation_file}\")\n",
        "    print(f\"    - Docker: /data/evaluation.bin (inside container)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No evaluation results found. Run the evaluation cycle cell first.\n"
          ]
        }
      ],
      "source": [
        "if 'evaluation_results' in globals() and evaluation_results:\n",
        "    print(\"Evaluation Submission Summary:\")\n",
        "    print(f\"  Total evaluations submitted: {len(evaluation_results)}\")\n",
        "    \n",
        "    successful = [r for r in evaluation_results if 'error' not in r]\n",
        "    errors = [r for r in evaluation_results if 'error' in r]\n",
        "    \n",
        "    print(f\"  Successful: {len(successful)}\")\n",
        "    print(f\"  Errors: {len(errors)}\")\n",
        "    \n",
        "    if successful:\n",
        "        print(\"\\n  Last successful evaluation metrics:\")\n",
        "        last = successful[-1]\n",
        "        for key in ['mse', 'coverage', 'avg_staleness', 'visit_count', 'matched_entries']:\n",
        "            if key in last:\n",
        "                print(f\"    {key}: {last[key]}\")\n",
        "    \n",
        "    if errors:\n",
        "        print(\"\\n  Errors encountered:\")\n",
        "        for err in errors:\n",
        "            print(f\"    {err.get('error', 'Unknown error')}\")\n",
        "    \n",
        "    print(\"\\n  Note: evaluation.bin is created by the server after processing.\")\n",
        "    print(\"  If the file doesn't exist, the server may:\")\n",
        "    print(\"    - Write it after the 60-second window\")\n",
        "    print(\"    - Require all evaluations to be within timing constraints\")\n",
        "    print(\"    - Only write if evaluations are valid\")\n",
        "else:\n",
        "    print(\"No evaluation results found. Run the evaluation cycle cell first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First evaluation: {'avg_staleness': 14990.0, 'coverage': 0.9137931034482759, 'covered_nodes': 53, 'matched_entries': 54, 'mse': 3.1844068470508164e-06, 'total_nodes': 58, 'visit_count': 54, 'elapsed_seconds': 14.84568977355957}\n",
            "Evaluation at 29.65s: MSE=3.1844068470508164e-06, Coverage=0.9137931034482759, Staleness=29834.98148148148\n",
            "Evaluation at 44.49s: MSE=3.1844068470508164e-06, Coverage=0.9137931034482759, Staleness=44683.0\n",
            "Evaluation at 59.34s: MSE=3.1844068470508164e-06, Coverage=0.9137931034482759, Staleness=59529.0\n",
            "Evaluation at 74.19s: MSE=3.1844068470508164e-06, Coverage=0.9137931034482759, Staleness=74376.51851851853\n",
            "Evaluation at 89.04s: MSE=N/A, Coverage=N/A, Staleness=N/A\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_staleness</th>\n",
              "      <th>coverage</th>\n",
              "      <th>covered_nodes</th>\n",
              "      <th>matched_entries</th>\n",
              "      <th>mse</th>\n",
              "      <th>total_nodes</th>\n",
              "      <th>visit_count</th>\n",
              "      <th>elapsed_seconds</th>\n",
              "      <th>error</th>\n",
              "      <th>detail</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14990.000000</td>\n",
              "      <td>0.913793</td>\n",
              "      <td>53.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>58.0</td>\n",
              "      <td>54</td>\n",
              "      <td>14.845690</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29834.981481</td>\n",
              "      <td>0.913793</td>\n",
              "      <td>53.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>58.0</td>\n",
              "      <td>54</td>\n",
              "      <td>29.646465</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44683.000000</td>\n",
              "      <td>0.913793</td>\n",
              "      <td>53.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>58.0</td>\n",
              "      <td>54</td>\n",
              "      <td>44.492140</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59529.000000</td>\n",
              "      <td>0.913793</td>\n",
              "      <td>53.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>58.0</td>\n",
              "      <td>54</td>\n",
              "      <td>59.339122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74376.518519</td>\n",
              "      <td>0.913793</td>\n",
              "      <td>53.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>58.0</td>\n",
              "      <td>54</td>\n",
              "      <td>74.186361</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54</td>\n",
              "      <td>89.043301</td>\n",
              "      <td>400 Client Error: Bad Request for url: http://...</td>\n",
              "      <td>{'error': 'Evaluation window has ended. No fur...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   avg_staleness  coverage  covered_nodes  matched_entries       mse  \\\n",
              "0   14990.000000  0.913793           53.0             54.0  0.000003   \n",
              "1   29834.981481  0.913793           53.0             54.0  0.000003   \n",
              "2   44683.000000  0.913793           53.0             54.0  0.000003   \n",
              "3   59529.000000  0.913793           53.0             54.0  0.000003   \n",
              "4   74376.518519  0.913793           53.0             54.0  0.000003   \n",
              "5            NaN       NaN            NaN              NaN       NaN   \n",
              "\n",
              "   total_nodes  visit_count  elapsed_seconds  \\\n",
              "0         58.0           54        14.845690   \n",
              "1         58.0           54        29.646465   \n",
              "2         58.0           54        44.492140   \n",
              "3         58.0           54        59.339122   \n",
              "4         58.0           54        74.186361   \n",
              "5          NaN           54        89.043301   \n",
              "\n",
              "                                               error  \\\n",
              "0                                                NaN   \n",
              "1                                                NaN   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "5  400 Client Error: Bad Request for url: http://...   \n",
              "\n",
              "                                              detail  \n",
              "0                                                NaN  \n",
              "1                                                NaN  \n",
              "2                                                NaN  \n",
              "3                                                NaN  \n",
              "4                                                NaN  \n",
              "5  {'error': 'Evaluation window has ended. No fur...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "crawler_eval = EfficientCrawler(seed_path=\"/\", revisit_window=5.0)\n",
        "visited_eval = crawler_eval.crawl(max_visits=10000)\n",
        "\n",
        "pagerank_scores_eval = crawler_eval.pagerank()\n",
        "\n",
        "first_visit_time = start_time\n",
        "evaluation_results = []\n",
        "\n",
        "elapsed = time.time() - first_visit_time\n",
        "if elapsed < 14.80:\n",
        "    time.sleep(14.80 - elapsed)\n",
        "\n",
        "result1 = submit_evaluation(crawler_eval, pagerank_scores_eval)\n",
        "result1[\"elapsed_seconds\"] = time.time() - first_visit_time\n",
        "result1[\"visit_count\"] = crawler_eval.page_visits\n",
        "evaluation_results.append(result1)\n",
        "print(f\"First evaluation: {result1}\")\n",
        "\n",
        "last_eval_time = time.time()\n",
        "while time.time() - first_visit_time <= 100.0:\n",
        "    time.sleep(14.80)\n",
        "    elapsed = time.time() - first_visit_time\n",
        "    if elapsed > 100.0:\n",
        "        break\n",
        "    \n",
        "    pagerank_scores_eval = crawler_eval.pagerank()\n",
        "    result = submit_evaluation(crawler_eval, pagerank_scores_eval)\n",
        "    result[\"elapsed_seconds\"] = elapsed\n",
        "    result[\"visit_count\"] = crawler_eval.page_visits\n",
        "    evaluation_results.append(result)\n",
        "    print(f\"Evaluation at {elapsed:.2f}s: MSE={result.get('mse', 'N/A')}, Coverage={result.get('coverage', 'N/A')}, Staleness={result.get('avg_staleness', 'N/A')}\")\n",
        "\n",
        "evaluation_summary = pd.DataFrame(evaluation_results)\n",
        "evaluation_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'crawler' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cycle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m      3\u001b[39m     time.sleep(\u001b[32m6\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     refresh_stats = \u001b[43mcrawler\u001b[49m.refresh_due_pages(max_visits=\u001b[32m20\u001b[39m)\n\u001b[32m      5\u001b[39m     summary = crawler.summary()\n\u001b[32m      6\u001b[39m     monitor_log.append({\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcycle\u001b[39m\u001b[33m\"\u001b[39m: cycle + \u001b[32m1\u001b[39m,\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrefreshed\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(refresh_stats[\u001b[33m\"\u001b[39m\u001b[33mrefreshed_paths\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtotal_updates\u001b[39m\u001b[33m\"\u001b[39m: summary[\u001b[33m\"\u001b[39m\u001b[33mnode_updates\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     13\u001b[39m     })\n",
            "\u001b[31mNameError\u001b[39m: name 'crawler' is not defined"
          ]
        }
      ],
      "source": [
        "monitor_log = []\n",
        "for cycle in range(3):\n",
        "    time.sleep(6)\n",
        "    refresh_stats = crawler.refresh_due_pages(max_visits=20)\n",
        "    summary = crawler.summary()\n",
        "    monitor_log.append({\n",
        "        \"cycle\": cycle + 1,\n",
        "        \"refreshed\": len(refresh_stats[\"refreshed_paths\"]),\n",
        "        \"updates_detected\": refresh_stats[\"updates_detected\"],\n",
        "        \"fetches\": refresh_stats[\"fetches\"],\n",
        "        \"total_page_visits\": summary[\"page_visits\"],\n",
        "        \"total_updates\": summary[\"node_updates\"],\n",
        "    })\n",
        "\n",
        "monitor_df = pd.DataFrame(monitor_log)\n",
        "monitor_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>page_id</th>\n",
              "      <th>last_node_id</th>\n",
              "      <th>updates_detected</th>\n",
              "      <th>last_change_ts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/page_50l53qgy</td>\n",
              "      <td>page_50l53qgy</td>\n",
              "      <td>yzh4ehzn3z05</td>\n",
              "      <td>2</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/page_h8jgjbdp</td>\n",
              "      <td>page_h8jgjbdp</td>\n",
              "      <td>wc7szvhh0o22</td>\n",
              "      <td>2</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/page_mhbm4c5c</td>\n",
              "      <td>page_mhbm4c5c</td>\n",
              "      <td>s8crs96rqi4i</td>\n",
              "      <td>2</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/page_mzxvzqz9</td>\n",
              "      <td>page_mzxvzqz9</td>\n",
              "      <td>4hjberq4igag</td>\n",
              "      <td>2</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/page_o79j1mj1</td>\n",
              "      <td>page_o79j1mj1</td>\n",
              "      <td>t5km0qa9cy1s</td>\n",
              "      <td>2</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/</td>\n",
              "      <td>page_bw9whgyj</td>\n",
              "      <td>z6ypla998j0m</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/page_clm8yl15</td>\n",
              "      <td>page_clm8yl15</td>\n",
              "      <td>nctov811i18x</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/page_oqaywqj1</td>\n",
              "      <td>page_oqaywqj1</td>\n",
              "      <td>gze8lvpzebfc</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/page_78y7rqpk</td>\n",
              "      <td>page_78y7rqpk</td>\n",
              "      <td>v85sa4k2cyx0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>/page_bw9whgyj</td>\n",
              "      <td>page_bw9whgyj</td>\n",
              "      <td>z6ypla998j0m</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>/page_q6oos6y7</td>\n",
              "      <td>page_q6oos6y7</td>\n",
              "      <td>j11luktcejch</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>/page_uud0wdo4</td>\n",
              "      <td>page_uud0wdo4</td>\n",
              "      <td>4zfvdzxxgimc</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>/page_y3p15zjd</td>\n",
              "      <td>page_y3p15zjd</td>\n",
              "      <td>adgxgkg6y8t0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>/page_amrqyyzh</td>\n",
              "      <td>page_amrqyyzh</td>\n",
              "      <td>lc30va5d0ydc</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>/page_b2ra9gc2</td>\n",
              "      <td>page_b2ra9gc2</td>\n",
              "      <td>08cb6cgs0qqn</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>/page_z70jrwf5</td>\n",
              "      <td>page_z70jrwf5</td>\n",
              "      <td>4jfv140hl64g</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>/page_8o013uo6</td>\n",
              "      <td>page_8o013uo6</td>\n",
              "      <td>ex78bryv4g14</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>/page_koyhs21y</td>\n",
              "      <td>page_koyhs21y</td>\n",
              "      <td>bri0ms89lvks</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>/page_wl5da40h</td>\n",
              "      <td>page_wl5da40h</td>\n",
              "      <td>7rq5o1n7pc2k</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>/page_h3vrwbe5</td>\n",
              "      <td>page_h3vrwbe5</td>\n",
              "      <td>c1bvdmj8c89i</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>/page_ior5x74y</td>\n",
              "      <td>page_ior5x74y</td>\n",
              "      <td>i7v0ww8fsiv3</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>/page_mvlri6sx</td>\n",
              "      <td>page_mvlri6sx</td>\n",
              "      <td>55m5chc86wio</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>/page_l2ca3nle</td>\n",
              "      <td>page_l2ca3nle</td>\n",
              "      <td>0nqh5s24ylt1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>/page_lrr8z2gr</td>\n",
              "      <td>page_lrr8z2gr</td>\n",
              "      <td>crkcpzh8z0po</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>/page_us4j9vjy</td>\n",
              "      <td>page_us4j9vjy</td>\n",
              "      <td>kii5dzx6nkmn</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>/page_79eqhbow</td>\n",
              "      <td>page_79eqhbow</td>\n",
              "      <td>cwq2h4g66yj6</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>/page_nahfqxul</td>\n",
              "      <td>page_nahfqxul</td>\n",
              "      <td>kffy9kb4vfwt</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>/page_r9l239qi</td>\n",
              "      <td>page_r9l239qi</td>\n",
              "      <td>bd01xrhbcz3x</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>/page_8pbgjasy</td>\n",
              "      <td>page_8pbgjasy</td>\n",
              "      <td>77bkr1u4uzlc</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>/page_fxzczsjj</td>\n",
              "      <td>page_fxzczsjj</td>\n",
              "      <td>rbn9rm9y1n0s</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>/page_08hem63t</td>\n",
              "      <td>page_08hem63t</td>\n",
              "      <td>otg7rc8sczah</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>/page_bq9rnfjd</td>\n",
              "      <td>page_bq9rnfjd</td>\n",
              "      <td>32m52wyq3zaq</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>/page_pywvoskb</td>\n",
              "      <td>page_pywvoskb</td>\n",
              "      <td>qpqct8ahlun1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>/page_xr36d0z1</td>\n",
              "      <td>page_xr36d0z1</td>\n",
              "      <td>h3m7uvczcsa7</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>/page_zqqwd2fp</td>\n",
              "      <td>page_zqqwd2fp</td>\n",
              "      <td>q7ho77igv6yz</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>/page_ugdzxjjl</td>\n",
              "      <td>page_ugdzxjjl</td>\n",
              "      <td>9gslan8fdzdz</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>/page_xlfkkfkt</td>\n",
              "      <td>page_xlfkkfkt</td>\n",
              "      <td>g3clc4pya136</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>/page_hqjqt683</td>\n",
              "      <td>page_hqjqt683</td>\n",
              "      <td>a7omrey22lk2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>/page_j4e76tqy</td>\n",
              "      <td>page_j4e76tqy</td>\n",
              "      <td>7sze9gyzt54r</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>/page_qsoosdyz</td>\n",
              "      <td>page_qsoosdyz</td>\n",
              "      <td>47tkuzuzuflh</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>/page_b25oft5l</td>\n",
              "      <td>page_b25oft5l</td>\n",
              "      <td>1nrej24v077l</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>/page_5tllgfyj</td>\n",
              "      <td>page_5tllgfyj</td>\n",
              "      <td>197bwl5pmwoc</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>/page_pxcvpd6y</td>\n",
              "      <td>page_pxcvpd6y</td>\n",
              "      <td>fposru5k47r7</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>/page_hjsv802n</td>\n",
              "      <td>page_hjsv802n</td>\n",
              "      <td>hlc8ckpxw43m</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>/page_nyipyqpz</td>\n",
              "      <td>page_nyipyqpz</td>\n",
              "      <td>4df9kgq0qmxs</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>/page_jmz5kdiv</td>\n",
              "      <td>page_jmz5kdiv</td>\n",
              "      <td>wgqsm926lins</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>/page_o9qjvp2p</td>\n",
              "      <td>page_o9qjvp2p</td>\n",
              "      <td>osc72wxlnfk6</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>/page_q3mn85z3</td>\n",
              "      <td>page_q3mn85z3</td>\n",
              "      <td>sphca6k08cbj</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>/page_1njo240c</td>\n",
              "      <td>page_1njo240c</td>\n",
              "      <td>9to5kyp2xwa2</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>/page_with03zm</td>\n",
              "      <td>page_with03zm</td>\n",
              "      <td>5zwh9s264zfq</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>/page_4bmfznui</td>\n",
              "      <td>page_4bmfznui</td>\n",
              "      <td>kxh4hspn3oko</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>/page_5wvxqfzg</td>\n",
              "      <td>page_5wvxqfzg</td>\n",
              "      <td>x0a4iw1oqquz</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>/page_i6govjun</td>\n",
              "      <td>page_i6govjun</td>\n",
              "      <td>7roz7ber56f9</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>/page_cr0npyvl</td>\n",
              "      <td>page_cr0npyvl</td>\n",
              "      <td>xf162ezmnd3x</td>\n",
              "      <td>1</td>\n",
              "      <td>1.763407e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              path        page_id  last_node_id  updates_detected  \\\n",
              "1   /page_50l53qgy  page_50l53qgy  yzh4ehzn3z05                 2   \n",
              "2   /page_h8jgjbdp  page_h8jgjbdp  wc7szvhh0o22                 2   \n",
              "4   /page_mhbm4c5c  page_mhbm4c5c  s8crs96rqi4i                 2   \n",
              "3   /page_mzxvzqz9  page_mzxvzqz9  4hjberq4igag                 2   \n",
              "5   /page_o79j1mj1  page_o79j1mj1  t5km0qa9cy1s                 2   \n",
              "0                /  page_bw9whgyj  z6ypla998j0m                 1   \n",
              "6   /page_clm8yl15  page_clm8yl15  nctov811i18x                 1   \n",
              "7   /page_oqaywqj1  page_oqaywqj1  gze8lvpzebfc                 1   \n",
              "8   /page_78y7rqpk  page_78y7rqpk  v85sa4k2cyx0                 1   \n",
              "9   /page_bw9whgyj  page_bw9whgyj  z6ypla998j0m                 1   \n",
              "10  /page_q6oos6y7  page_q6oos6y7  j11luktcejch                 1   \n",
              "11  /page_uud0wdo4  page_uud0wdo4  4zfvdzxxgimc                 1   \n",
              "12  /page_y3p15zjd  page_y3p15zjd  adgxgkg6y8t0                 1   \n",
              "13  /page_amrqyyzh  page_amrqyyzh  lc30va5d0ydc                 1   \n",
              "14  /page_b2ra9gc2  page_b2ra9gc2  08cb6cgs0qqn                 1   \n",
              "15  /page_z70jrwf5  page_z70jrwf5  4jfv140hl64g                 1   \n",
              "16  /page_8o013uo6  page_8o013uo6  ex78bryv4g14                 1   \n",
              "17  /page_koyhs21y  page_koyhs21y  bri0ms89lvks                 1   \n",
              "18  /page_wl5da40h  page_wl5da40h  7rq5o1n7pc2k                 1   \n",
              "19  /page_h3vrwbe5  page_h3vrwbe5  c1bvdmj8c89i                 1   \n",
              "20  /page_ior5x74y  page_ior5x74y  i7v0ww8fsiv3                 1   \n",
              "21  /page_mvlri6sx  page_mvlri6sx  55m5chc86wio                 1   \n",
              "22  /page_l2ca3nle  page_l2ca3nle  0nqh5s24ylt1                 1   \n",
              "23  /page_lrr8z2gr  page_lrr8z2gr  crkcpzh8z0po                 1   \n",
              "24  /page_us4j9vjy  page_us4j9vjy  kii5dzx6nkmn                 1   \n",
              "25  /page_79eqhbow  page_79eqhbow  cwq2h4g66yj6                 1   \n",
              "26  /page_nahfqxul  page_nahfqxul  kffy9kb4vfwt                 1   \n",
              "27  /page_r9l239qi  page_r9l239qi  bd01xrhbcz3x                 1   \n",
              "28  /page_8pbgjasy  page_8pbgjasy  77bkr1u4uzlc                 1   \n",
              "29  /page_fxzczsjj  page_fxzczsjj  rbn9rm9y1n0s                 1   \n",
              "30  /page_08hem63t  page_08hem63t  otg7rc8sczah                 1   \n",
              "31  /page_bq9rnfjd  page_bq9rnfjd  32m52wyq3zaq                 1   \n",
              "32  /page_pywvoskb  page_pywvoskb  qpqct8ahlun1                 1   \n",
              "33  /page_xr36d0z1  page_xr36d0z1  h3m7uvczcsa7                 1   \n",
              "34  /page_zqqwd2fp  page_zqqwd2fp  q7ho77igv6yz                 1   \n",
              "35  /page_ugdzxjjl  page_ugdzxjjl  9gslan8fdzdz                 1   \n",
              "36  /page_xlfkkfkt  page_xlfkkfkt  g3clc4pya136                 1   \n",
              "37  /page_hqjqt683  page_hqjqt683  a7omrey22lk2                 1   \n",
              "38  /page_j4e76tqy  page_j4e76tqy  7sze9gyzt54r                 1   \n",
              "39  /page_qsoosdyz  page_qsoosdyz  47tkuzuzuflh                 1   \n",
              "40  /page_b25oft5l  page_b25oft5l  1nrej24v077l                 1   \n",
              "41  /page_5tllgfyj  page_5tllgfyj  197bwl5pmwoc                 1   \n",
              "42  /page_pxcvpd6y  page_pxcvpd6y  fposru5k47r7                 1   \n",
              "43  /page_hjsv802n  page_hjsv802n  hlc8ckpxw43m                 1   \n",
              "44  /page_nyipyqpz  page_nyipyqpz  4df9kgq0qmxs                 1   \n",
              "45  /page_jmz5kdiv  page_jmz5kdiv  wgqsm926lins                 1   \n",
              "46  /page_o9qjvp2p  page_o9qjvp2p  osc72wxlnfk6                 1   \n",
              "47  /page_q3mn85z3  page_q3mn85z3  sphca6k08cbj                 1   \n",
              "48  /page_1njo240c  page_1njo240c  9to5kyp2xwa2                 1   \n",
              "49  /page_with03zm  page_with03zm  5zwh9s264zfq                 1   \n",
              "50  /page_4bmfznui  page_4bmfznui  kxh4hspn3oko                 1   \n",
              "51  /page_5wvxqfzg  page_5wvxqfzg  x0a4iw1oqquz                 1   \n",
              "52  /page_i6govjun  page_i6govjun  7roz7ber56f9                 1   \n",
              "53  /page_cr0npyvl  page_cr0npyvl  xf162ezmnd3x                 1   \n",
              "\n",
              "    last_change_ts  \n",
              "1     1.763407e+09  \n",
              "2     1.763407e+09  \n",
              "4     1.763407e+09  \n",
              "3     1.763407e+09  \n",
              "5     1.763407e+09  \n",
              "0     1.763407e+09  \n",
              "6     1.763407e+09  \n",
              "7     1.763407e+09  \n",
              "8     1.763407e+09  \n",
              "9     1.763407e+09  \n",
              "10    1.763407e+09  \n",
              "11    1.763407e+09  \n",
              "12    1.763407e+09  \n",
              "13    1.763407e+09  \n",
              "14    1.763407e+09  \n",
              "15    1.763407e+09  \n",
              "16    1.763407e+09  \n",
              "17    1.763407e+09  \n",
              "18    1.763407e+09  \n",
              "19    1.763407e+09  \n",
              "20    1.763407e+09  \n",
              "21    1.763407e+09  \n",
              "22    1.763407e+09  \n",
              "23    1.763407e+09  \n",
              "24    1.763407e+09  \n",
              "25    1.763407e+09  \n",
              "26    1.763407e+09  \n",
              "27    1.763407e+09  \n",
              "28    1.763407e+09  \n",
              "29    1.763407e+09  \n",
              "30    1.763407e+09  \n",
              "31    1.763407e+09  \n",
              "32    1.763407e+09  \n",
              "33    1.763407e+09  \n",
              "34    1.763407e+09  \n",
              "35    1.763407e+09  \n",
              "36    1.763407e+09  \n",
              "37    1.763407e+09  \n",
              "38    1.763407e+09  \n",
              "39    1.763407e+09  \n",
              "40    1.763407e+09  \n",
              "41    1.763407e+09  \n",
              "42    1.763407e+09  \n",
              "43    1.763407e+09  \n",
              "44    1.763407e+09  \n",
              "45    1.763407e+09  \n",
              "46    1.763407e+09  \n",
              "47    1.763407e+09  \n",
              "48    1.763407e+09  \n",
              "49    1.763407e+09  \n",
              "50    1.763407e+09  \n",
              "51    1.763407e+09  \n",
              "52    1.763407e+09  \n",
              "53    1.763407e+09  "
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "updated_pages = [\n",
        "    {\n",
        "        \"path\": path,\n",
        "        \"page_id\": state.page_id,\n",
        "        \"last_node_id\": state.last_node_id,\n",
        "        \"updates_detected\": state.updates_detected,\n",
        "        \"last_change_ts\": state.last_changed_ts,\n",
        "    }\n",
        "    for path, state in crawler.pages.items()\n",
        "    if state.updates_detected > 0\n",
        "]\n",
        "\n",
        "updated_pages_df = pd.DataFrame(updated_pages)\n",
        "updated_pages_df.sort_values(\"updates_detected\", ascending=False) if not updated_pages_df.empty else \"No node-id updates observed during monitoring window.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'unique_pages': 54,\n",
              " 'page_visits': 114,\n",
              " 'node_updates': 59,\n",
              " 'average_out_degree': 3.3333333333333335}"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_summary = crawler.summary()\n",
        "final_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'due_count': 14,\n",
              " 'sample': ['/page_clm8yl15',\n",
              "  '/page_oqaywqj1',\n",
              "  '/page_78y7rqpk',\n",
              "  '/page_bw9whgyj',\n",
              "  '/page_q6oos6y7']}"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def pages_due_for_refresh(crawler: EfficientCrawler, horizon: float = 120.0):\n",
        "    now = time.time()\n",
        "    due = []\n",
        "    for path, state in crawler.pages.items():\n",
        "        if now - state.last_fetched_ts >= horizon:\n",
        "            due.append(path)\n",
        "    return due\n",
        "\n",
        "pending_refresh = pages_due_for_refresh(crawler, horizon=10.0)\n",
        "{\"due_count\": len(pending_refresh), \"sample\": pending_refresh[:5]}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
